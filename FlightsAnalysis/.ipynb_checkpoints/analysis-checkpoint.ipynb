{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce78781-1e85-4081-b789-6a934f25f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"flights\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fae416c0-f172-4589-956e-5df0e7d03897",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = \"data/departuredelays.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01fee428-8f71-47e5-bb31-454cc6215abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\").option(\"header\", \"true\").load(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c7774b-a7d0-4b1e-9fb9-3e81ca183d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"us_delay_flights_tbl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b241289b-11e7-4e25-bd88-54a9bbb9940f",
   "metadata": {},
   "source": [
    "The US flight delays data set has five columns:\n",
    "\n",
    "• The date column contains a string like 02190925. When converted, this maps to\n",
    "02-19 09:25 am.\n",
    "\n",
    "• The delay column gives the delay in minutes between the scheduled and actual\n",
    "departure times. Early departures show negative numbers.\n",
    "\n",
    "• The distance column gives the distance in miles from the origin airport to the\n",
    "destination airport.\n",
    "\n",
    "• The origin column contains the origin IATA airport code.\n",
    "\n",
    "• The destination column contains the destination IATA airport code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d442056f-e4d3-459a-bcca-0aaf9aae106a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011245|    6|     602|   ABE|        ATL|\n",
      "|1020600|   -8|     369|   ABE|        DTW|\n",
      "|1021245|   -2|     602|   ABE|        ATL|\n",
      "|1020605|   -4|     602|   ABE|        ATL|\n",
      "|1031245|   -4|     602|   ABE|        ATL|\n",
      "|1030605|    0|     602|   ABE|        ATL|\n",
      "|1041243|   10|     602|   ABE|        ATL|\n",
      "|1040605|   28|     602|   ABE|        ATL|\n",
      "|1051245|   88|     602|   ABE|        ATL|\n",
      "|1050605|    9|     602|   ABE|        ATL|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7013c257-3279-4de3-80be-66336f1d89a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+-----------+\n",
      "|distance|origin|destination|\n",
      "+--------+------+-----------+\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "|    4330|   HNL|        JFK|\n",
      "+--------+------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Flights whose distance is greater than 1k miles\n",
    "spark.sql(\"\"\"SELECT distance, origin, destination FROM us_delay_flights_tbl WHERE distance > 1000 ORDER BY distance DESC\"\"\").show(10)\n",
    "\n",
    "from pyspark.sql.functions import col, desc\n",
    "(df.select(\"distance\", \"origin\", \"destination\")\n",
    ".where(col(\"distance\") > 1000)\n",
    ".orderBy(desc(\"distance\"))).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c310752-a955-4b6b-afa9-d09607fd0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+\n",
      "|   date|delay|distance|origin|destination|\n",
      "+-------+-----+--------+------+-----------+\n",
      "|1011410|  124|    1604|   SFO|        ORD|\n",
      "|1022330|  326|    1604|   SFO|        ORD|\n",
      "|1021410|  190|    1604|   SFO|        ORD|\n",
      "|1101410|  184|    1604|   SFO|        ORD|\n",
      "|1190925|  297|    1604|   SFO|        ORD|\n",
      "|1241110|  139|    1604|   SFO|        ORD|\n",
      "|1301800|  167|    1604|   SFO|        ORD|\n",
      "|1011237|  122|    1604|   SFO|        ORD|\n",
      "|1032258|  163|    1604|   SFO|        ORD|\n",
      "|1031920|  193|    1604|   SFO|        ORD|\n",
      "+-------+-----+--------+------+-----------+\n",
      "only showing top 10 rows\n",
      "+--------+------+-----------+-----+-------+\n",
      "|distance|origin|destination|delay|   date|\n",
      "+--------+------+-----------+-----+-------+\n",
      "|    1604|   SFO|        ORD|  124|1011410|\n",
      "|    1604|   SFO|        ORD|  326|1022330|\n",
      "|    1604|   SFO|        ORD|  190|1021410|\n",
      "|    1604|   SFO|        ORD|  184|1101410|\n",
      "|    1604|   SFO|        ORD|  297|1190925|\n",
      "|    1604|   SFO|        ORD|  139|1241110|\n",
      "|    1604|   SFO|        ORD|  167|1301800|\n",
      "|    1604|   SFO|        ORD|  122|1011237|\n",
      "|    1604|   SFO|        ORD|  163|1032258|\n",
      "|    1604|   SFO|        ORD|  193|1031920|\n",
      "+--------+------+-----------+-----+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# ALl flights between san francisco (SFO) and chicago (ORD) with 2 hour delay\n",
    "spark.sql(\"\"\"SELECT * FROM us_delay_flights_tbl WHERE origin='SFO' AND destination='ORD' AND delay>120\"\"\").show(10)\n",
    "from pyspark.sql.functions import col, desc\n",
    "df.select(\"distance\", \"origin\", \"destination\", \"delay\", \"date\").where(col(\"origin\") == \"SFO\").where(col(\"destination\")==\"ORD\").where(col(\"delay\") > 120).show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895b4cf-3af7-423c-8799-4016edd2645e",
   "metadata": {},
   "source": [
    " label all US flights, regardless of origin and destination,\n",
    "with an indication of the delays they experienced: Very Long Delays (> 6 hours),\n",
    "Long Delays (2–6 hours), etc. We’ll add these human-readable labels in a new column\n",
    "called Flight_Delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70425849-92c3-487e-a073-91cb707b5d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+--------+------+-----------+-------------+\n",
      "|   date|delay|distance|origin|destination|Flight_Delays|\n",
      "+-------+-----+--------+------+-----------+-------------+\n",
      "|1220625|  333|     602|   ABE|        ATL|  Long Delays|\n",
      "|2120625|  305|     602|   ABE|        ATL|  Long Delays|\n",
      "|3021725|  275|     602|   ABE|        ATL|  Long Delays|\n",
      "|2150625|  257|     602|   ABE|        ATL|  Long Delays|\n",
      "|2211215|  247|     602|   ABE|        ATL|  Long Delays|\n",
      "|2211245|  247|     369|   ABE|        DTW|  Long Delays|\n",
      "|1220607|  219|     569|   ABE|        ORD|  Long Delays|\n",
      "|3201725|  211|     602|   ABE|        ATL|  Long Delays|\n",
      "|3121245|  197|     369|   ABE|        DTW|  Long Delays|\n",
      "|2141628|  192|     569|   ABE|        ORD|  Long Delays|\n",
      "+-------+-----+--------+------+-----------+-------------+\n",
      "only showing top 10 rows\n",
      "+-------+-----+--------+------+-----------+-------------+\n",
      "|   date|delay|distance|origin|destination|Flight_Delays|\n",
      "+-------+-----+--------+------+-----------+-------------+\n",
      "|1220625|  333|     602|   ABE|        ATL|  Long Delays|\n",
      "|2120625|  305|     602|   ABE|        ATL|  Long Delays|\n",
      "|3021725|  275|     602|   ABE|        ATL|  Long Delays|\n",
      "|2150625|  257|     602|   ABE|        ATL|  Long Delays|\n",
      "|2211215|  247|     602|   ABE|        ATL|  Long Delays|\n",
      "|2211245|  247|     369|   ABE|        DTW|  Long Delays|\n",
      "|1220607|  219|     569|   ABE|        ORD|  Long Delays|\n",
      "|3201725|  211|     602|   ABE|        ATL|  Long Delays|\n",
      "|3121245|  197|     369|   ABE|        DTW|  Long Delays|\n",
      "|2141628|  192|     569|   ABE|        ORD|  Long Delays|\n",
      "+-------+-----+--------+------+-----------+-------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT *,\n",
    "CASE\n",
    "    WHEN delay > 360 THEN 'Very Long Delays'\n",
    "    WHEN delay > 120 AND delay < 360 THEN 'Long Delays'\n",
    "    WHEN delay > 60 and delay < 120 THEN 'Short Delays'\n",
    "    WHEN delay > 0 and delay < 60 THEN 'Tolerable Delays'\n",
    "    WHEN delay=0 THEN 'No Delays'\n",
    "    ELSE 'Early'\n",
    "END AS Flight_Delays\n",
    "FROM us_delay_flights_tbl\n",
    "ORDER BY origin, delay DESC\"\"\").show(10)\n",
    "\n",
    "from pyspark.sql.functions import col, desc, when\n",
    "df.withColumn(\n",
    "    \"Flight_Delays\",\n",
    "    when(col(\"delay\") > 360, \"Very Long Delays\")\n",
    "    .when((col(\"delay\") > 120) & (col(\"delay\") <= 360), \"Long Delays\")\n",
    "    .when((col(\"delay\") > 60) & (col(\"delay\") <= 120), \"Short Delays\")\n",
    "    .when((col(\"delay\") > 0) & (col(\"delay\") <= 60), \"Tolerable Delays\")\n",
    "    .when(col(\"delay\") == 0, \"No Delays\")\n",
    "    .otherwise(\"Early\")\n",
    ").orderBy(col(\"origin\"), col(\"delay\").desc()).show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e22a3be-031c-4bb8-961e-3106e2422e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With each table spark has metadata, table, schema, description columns, partitions, physical locations\n",
    "# All stored in metastore\n",
    "# Spark by default uses Apache have metastore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2877a5a-7a8a-474f-93a3-ffcacb4be021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
